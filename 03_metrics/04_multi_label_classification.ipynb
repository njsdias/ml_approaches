{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Label Classification\n",
    "\n",
    "In multi-label classification, each sample can have one or more\n",
    "classes associated with it. One simple example of this type of problem would be a\n",
    "task in which you are asked to predict different objects in a given image.\n",
    "\n",
    "Imagine an image where we \n",
    "have a chair, flower-pot, window, but we don’t have other objects such as computer,\n",
    "bed, tv, etc. So, one image can have multiple targets associated with it. This type of\n",
    "problem is the multi-label classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics for this type of classification problem are a bit different. Some suitable\n",
    "and most common metrics are:\n",
    "- Precision at k (P@k)\n",
    "- Average precision at k (AP@k)\n",
    "- Mean average precision at k (MAP@k)\n",
    "- Log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision at k (P@k)\n",
    "\n",
    "If you have a list of original classes for a given\n",
    "sample and list of predicted classes for the same, precision is defined as the number\n",
    "of hits in the predicted list considering only top-k predictions, divided by k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: precision at a given value k\n",
    "    \"\"\"\n",
    "    \n",
    "    # if k is 0, return 0. we should never have this\n",
    "    # as k is always >= 1\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    \n",
    "    # we are interested only in top-k predictions\n",
    "    y_pred = y_pred[:k]\n",
    "    \n",
    "    # convert predictions to set\n",
    "    pred_set = set(y_pred)\n",
    "    \n",
    "    # convert actual values to set\n",
    "    true_set = set(y_true)\n",
    "    \n",
    "    # find common values\n",
    "    common_values = pred_set.intersection(true_set)\n",
    "    \n",
    "    # return length of common values over k\n",
    "    return len(common_values) / len(y_pred[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average precision at k (AP@k) \n",
    "\n",
    "AP@k is calculated using P@k.\n",
    "For example, if we have to calculate AP@3, we calculate AP@1, AP@2 and AP@3\n",
    "and then divide the sum by 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates average precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: average precision at a given value k\n",
    "    \"\"\"\n",
    "    # initialize p@k list of values\n",
    "    pk_values = []\n",
    "    \n",
    "    # loop over all k. from 1 to k + 1\n",
    "    for i in range(1, k + 1):\n",
    "        # calculate p@i and append to list\n",
    "        pk_values.append(pk(y_true, y_pred, i))\n",
    "        \n",
    "    # if we have no values in the list, return 0\n",
    "    if len(pk_values) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # else, we return the sum of list over\n",
    "    return sum(pk_values) / len(pk_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        y_true=[1, 2, 3],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@1=0.0\n",
      "\n",
      "        y_true=[1, 2, 3],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@2=0.25\n",
      "\n",
      "        y_true=[1, 2, 3],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@3=0.38888888888888884\n",
      "\n",
      "        y_true=[0, 2],\n",
      "        y_pred=[1],\n",
      "        AP@1=0.0\n",
      "\n",
      "        y_true=[0, 2],\n",
      "        y_pred=[1],\n",
      "        AP@2=0.0\n",
      "\n",
      "        y_true=[0, 2],\n",
      "        y_pred=[1],\n",
      "        AP@3=0.0\n",
      "\n",
      "        y_true=[1],\n",
      "        y_pred=[0, 2, 3],\n",
      "        AP@1=0.0\n",
      "\n",
      "        y_true=[1],\n",
      "        y_pred=[0, 2, 3],\n",
      "        AP@2=0.0\n",
      "\n",
      "        y_true=[1],\n",
      "        y_pred=[0, 2, 3],\n",
      "        AP@3=0.0\n",
      "\n",
      "        y_true=[2, 3],\n",
      "        y_pred=[2, 3, 4, 0],\n",
      "        AP@1=1.0\n",
      "\n",
      "        y_true=[2, 3],\n",
      "        y_pred=[2, 3, 4, 0],\n",
      "        AP@2=1.0\n",
      "\n",
      "        y_true=[2, 3],\n",
      "        y_pred=[2, 3, 4, 0],\n",
      "        AP@3=0.8888888888888888\n",
      "\n",
      "        y_true=[1, 0],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@1=1.0\n",
      "\n",
      "        y_true=[1, 0],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@2=1.0\n",
      "\n",
      "        y_true=[1, 0],\n",
      "        y_pred=[0, 1, 2],\n",
      "        AP@3=0.8888888888888888\n",
      "\n",
      "        y_true=[],\n",
      "        y_pred=[0],\n",
      "        AP@1=0.0\n",
      "\n",
      "        y_true=[],\n",
      "        y_pred=[0],\n",
      "        AP@2=0.0\n",
      "\n",
      "        y_true=[],\n",
      "        y_pred=[0],\n",
      "        AP@3=0.0\n"
     ]
    }
   ],
   "source": [
    "y_true = [[1, 2, 3], [0, 2], [1], [2, 3], [1, 0],[]]\n",
    "\n",
    "y_pred = [[0, 1, 2],[1], [0, 2, 3], [2, 3, 4, 0],[0, 1, 2], [0]]\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    for j in range(1, 4):\n",
    "        print(f\"\"\"\n",
    "        y_true={y_true[i]},\n",
    "        y_pred={y_pred[i]},\n",
    "        AP@{j}={apk(y_true[i], y_pred[i], k=j)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean average precision at k (MAP@k)\n",
    "In machine learning, we are interested in all samples, and that’s why we have mean average precision \n",
    "at k or MAP@k. MAP@k is just an average of AP@k and can be calculated easily by the following python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    This function calculates mean avg precision at k\n",
    "    for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: mean avg precision at a given value k\n",
    "    \"\"\"\n",
    "    # initialize empty list for apk values\n",
    "    apk_values = []\n",
    "    \n",
    "    # loop over all samples\n",
    "    for i in range(len(y_true)):\n",
    "        # store apk values for every sample\n",
    "        apk_values.append(apk(y_true[i], y_pred[i], k=k))\n",
    "        \n",
    "    # return mean of apk values list\n",
    "    return sum(apk_values) / len(apk_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.375\n",
      "0.3611111111111111\n",
      "0.34722222222222215\n"
     ]
    }
   ],
   "source": [
    "print(mapk(y_true, y_pred, k=1))\n",
    "print(mapk(y_true, y_pred, k=2))\n",
    "print(mapk(y_true, y_pred, k=3))\n",
    "print(mapk(y_true, y_pred, k=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P@k, AP@k and MAP@k all range from 0 to 1 with 1 being the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that sometimes you might see different implementations of P@k and\n",
    "AP@k on the internet. For example, let’s take a look at one of these\n",
    "implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is another version of AP@k where order matters and we weigh\n",
    "the predictions. This implementation will have slightly different results from what\n",
    "I have presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from:\n",
    "# https://github.com/benhamner/Metrics/blob/\n",
    "# master/Python/ml_metrics/average_precision.py\n",
    "import numpy as np\n",
    "    def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the AP at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "    A list of elements to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "    A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "    The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "    \n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    \n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    \n",
    "    return score / min(len(actual), k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log loss for multi-label classification\n",
    "\n",
    "You can convert the targets to binary format and then use a log loss for each column. In\n",
    "the end, you can take the average of log loss in each column. This is also known as\n",
    "**mean column-wise log loss**. \n",
    "\n",
    "Of course, there are other ways you can implement this,\n",
    "and you should explore it as you come across it.\n",
    "\n",
    "We have now reached a stage where we can say that we now know all binary, multi-\n",
    "class and multi-label classification metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
