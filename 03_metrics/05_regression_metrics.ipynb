{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Regression Problems\n",
    "\n",
    "- **MAE**: Mean Absolute Error\n",
    "- **MSE**: Mean Squared Error   \n",
    "- **RMSE**: Root Mean Squared Error\n",
    "- **MSLE**: Mean Squared Logarithmic Error\n",
    "- **RMSLE**: Root Mean Squared Logarithmic Error\n",
    "- **MAPE**: Mean Absolute Percentage Error\n",
    "- **R²**: R squared\n",
    "- **MCC**: Matthew’s Correlation Coefficient\n",
    "- **QWK**: Quadratic Weighted kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE: Mean Absolute Error\n",
    "\n",
    "$$ MAE = abs(True Value - Predicted Value) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mae\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute error\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop overa ll samples in the true and prdicted list\n",
    "    for y_t, yp in zip(y_treu, y_pred):\n",
    "        # calculate absolute error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp)\n",
    "        \n",
    "    # return mean error\n",
    "    return error/ len(y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE: Mean Squared Error\n",
    "\n",
    "$$ MSE = (True Value - Predicted Value)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mse\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean squared error\n",
    "    \"\"\"\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in the true and predicted list\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared error\n",
    "        # and add to error\n",
    "        error += (yt - yp) ** 2\n",
    "    \n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE: Root Mean Squared Error\n",
    "\n",
    "$$RMSE= \\sqrt{MSE}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSLE: Mean Squared Logarithmic Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_log_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates msle\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean squared logarithmic error\n",
    "\n",
    "    \"\"\"\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate squared log error\n",
    "        # and add to error\n",
    "        error += (np.log(1 + yt) - np.log(1 + yp)) ** 2\n",
    "    \n",
    "    # return mean error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSLE: Root Mean Squared Logarithmic Error\n",
    "\n",
    "$$Percentage Error = ( ( True Value – Predicted Value ) / True Value ) * 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates mpe\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean percentage error\n",
    "    \"\"\"\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "    # calculate percentage error\n",
    "    # and add to error\n",
    "    error += (yt - yp) / yt\n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE: Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_abs_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates MAPE\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute percentage error\n",
    "    \"\"\"\n",
    "    # initialize error at 0\n",
    "    error = 0\n",
    "    \n",
    "    # loop over all samples in true and predicted list\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # calculate percentage error\n",
    "        # and add to error\n",
    "        error += np.abs(yt - yp) / yt\n",
    "    \n",
    "    # return mean percentage error\n",
    "    return error / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$: R-squared\n",
    "\n",
    "In simple words, R-squared says how good your model fits the data. R-squared\n",
    "closer to 1.0 says that the model fits the data quite well, whereas closer 0 means\n",
    "that model isn’t that good.\n",
    "\n",
    "$$ R^2 = 1 -\\frac{\\sum^{N}_{i=1} (y_{t_{i}} - y_{p_{i}})^2}{\\sum^{N}_{i=1} (y_{t_{i}} - y_{t_{mean}})^2}                $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates r-squared score\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: r2 score\n",
    "    \"\"\"\n",
    "    # calculate the mean value of true values\n",
    "    mean_true_value = np.mean(y_true)\n",
    "    \n",
    "    # initialize numerator with 0\n",
    "    numerator = 0\n",
    "    \n",
    "    # initialize denominator with 0\n",
    "    denominator = 0\n",
    "    \n",
    "    # loop over all true and predicted values\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # update numerator\n",
    "        numerator += (yt - yp) ** 2\n",
    "        # update denominator\n",
    "        denominator += (yt - mean_true_value) ** 2\n",
    "        \n",
    "    # calculate the ratio\n",
    "    ratio = numerator / denominator\n",
    "    \n",
    "    # return 1 - ratio\n",
    "    return 1 – ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this metrics are implemented in sklearn, for example:\n",
    "\n",
    "```def mae_np(y_true, y_pred):\n",
    "        return np.mean(np.abs(y_true - y_pred))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK: Quadratic Weighted kappa (Cohen’s kappa)\n",
    "\n",
    "Measures the agreement between two ratings.\n",
    "\n",
    "The ratings can be any real numbers in 0 to N. And\n",
    "predictions are also in the same range. An agreement can be defined as how close\n",
    "these ratings are to each other. So, it’s **suitable for a classification problem with N\n",
    "different categories/classes**. \n",
    "\n",
    "If the agreement is high, the score is closer towards 1.0.\n",
    "In the case of low agreement, the score is close to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens Kappa 0.33333333333333337\n",
      "Accuracy Score 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]\n",
    "\n",
    "qwk = metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "print('Cohens Kappa', qwk)\n",
    "print('Accuracy Score', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even though accuracy is high, QWK is less. A QWK greater than\n",
    "0.85 is considered to be very good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC: Matthew’s Correlation Coefficient\n",
    "\n",
    "MCC ranges from -1 to 1. 1 is perfect prediction, -1 is imperfect prediction, and 0 is random\n",
    "prediction.\n",
    "\n",
    "        \n",
    "$$ MCC = \\frac{TP \\times TN - FP \\times FN}{[ (TP + FP) \\times (FN + TN) \\times (FP + TN) \\times (TP + FN) ] ^ {0.5}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates Matthew's Correlation Coefficient\n",
    "    for binary classification.\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: mcc score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "\n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "\n",
    "    denominator = ( (tp + fp) * (fn + tn) * (fp + tn) * (tp + fn) )\n",
    "\n",
    "    denominator = denominator ** 0.5\n",
    "\n",
    "return numerator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to keep in mind is that to evaluate unsupervised methods, for example,\n",
    "some kind of clustering, it’s better to create or manually label the test set and keep\n",
    "it separate from everything that is going on in your modelling part. \n",
    "\n",
    "When you are\n",
    "done with clustering, you can evaluate the performance on the test set simply by\n",
    "using any of the supervised learning metrics.\n",
    "\n",
    "Once we understand what metric to use for a given problem, we can start looking\n",
    "more deeply into our models for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
