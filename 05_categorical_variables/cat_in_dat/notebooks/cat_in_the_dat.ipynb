{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "The dataset consists of all kinds of categorical variables:\n",
    "- Nominal: the order is not important (male, female)\n",
    "- Ordinal: the order is important (novice, expert, contribute)\n",
    "- Cyclical: days, months\n",
    "- Binary\n",
    "\n",
    "Overall, there are:\n",
    "- Five binary variables\n",
    "- Ten nominal variables\n",
    "- Six ordinal variables\n",
    "- Two cyclic variables\n",
    "- And a target variable\n",
    "\n",
    "For categories that are in text we need to convert them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "## Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('../input/cat_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>02e7c8990</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>c</td>\n",
       "      <td>U</td>\n",
       "      <td>Pw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Star</td>\n",
       "      <td>Axolotl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>f37df64af</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>e</td>\n",
       "      <td>X</td>\n",
       "      <td>pE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>n</td>\n",
       "      <td>P</td>\n",
       "      <td>eN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>f9d456e57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>...</td>\n",
       "      <td>c5361037c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>C</td>\n",
       "      <td>OZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2       nom_3  \\\n",
       "0   0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster      Russia   \n",
       "1   1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl         NaN   \n",
       "2   2    0.0    1.0    0.0     F     N   Red        NaN  Hamster      Canada   \n",
       "3   3    NaN    0.0    0.0     F     N   Red     Circle  Hamster     Finland   \n",
       "4   4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster  Costa Rica   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1     ord_2 ord_3 ord_4  ord_5  day month  \\\n",
       "0  ...  02e7c8990   3.0  Contributor       Hot     c     U     Pw  6.0   3.0   \n",
       "1  ...  f37df64af   3.0  Grandmaster      Warm     e     X     pE  7.0   7.0   \n",
       "2  ...        NaN   3.0          NaN  Freezing     n     P     eN  5.0   9.0   \n",
       "3  ...  f9d456e57   1.0       Novice  Lava Hot     a     C    NaN  3.0   3.0   \n",
       "4  ...  c5361037c   3.0  Grandmaster      Cold     h     C     OZ  5.0  12.0   \n",
       "\n",
       "  target  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASRElEQVR4nO3df6xnd13n8eerHUpBKJ3S2Yoz1Wl04mZkpdJrOytmoyW20646jQIpETvihNFQNhqNWozZ7ha7wYgiRWgysbUzZrUWEDuQwuykoGSNA70D2J82vRZqZ1KYcaa0ICls8b1/fD9Tv9x+751b+Hy/37l3no/km3vO+3zO+Xy+yUxeOed8zvmmqpAkqadTpj0ASdLKY7hIkrozXCRJ3RkukqTuDBdJUnerpj2AE8XZZ59d69evn/YwJGlZ2b9//79U1Zr5dcOlWb9+PbOzs9MehiQtK0keGVUf62WxJJ9Pck+SzyaZbbWzkuxN8lD7u7rVk+SGJHNJ7k7yyqHjbG3tH0qydah+QTv+XNs3i/UhSZqMSdxz+fGqOr+qZtr6NcCdVbUBuLOtA1wGbGif7cCNMAgK4FrgIuBC4NqhsLgReNPQfpuP04ckaQKmcUN/C7CzLe8Erhiq76qBfcCZSV4GXArsraqjVfU4sBfY3LadUVX7avCagV3zjjWqD0nSBIw7XAr4P0n2J9neaudU1WNt+QvAOW15LfDo0L4HWm2x+oER9cX6+CZJtieZTTJ7+PDh5/zlJEmjjfuG/o9W1cEk/wHYm+QfhzdWVSUZ68vNFuujqnYAOwBmZmZ8yZokdTLWM5eqOtj+HgI+yOCeyRfbJS3a30Ot+UHg3KHd17XaYvV1I+os0ockaQLGFi5JviPJi48tA5cA9wK7gWMzvrYCt7fl3cBVbdbYJuCJdmlrD3BJktXtRv4lwJ627ckkm9ossavmHWtUH5KkCRjnZbFzgA+22cGrgD+vqo8muQu4Lck24BHgda39HcDlwBzwVeCNAFV1NMnbgLtau+uq6mhbfjNwC/AC4CPtA/D2BfqQJE1A/D2XgZmZmfIhSkl6bpLsH3rU5Bk+od/RBb+xa9pD0Alm/+9fNe0hSFPhiyslSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd2NPVySnJrkM0k+3NbPS/LJJHNJ/jLJaa3+/LY+17avHzrGW1v9wSSXDtU3t9pckmuG6iP7kCRNxiTOXH4FeGBo/feAd1bV9wGPA9tafRvweKu/s7UjyUbgSuAHgM3Ae1tgnQq8B7gM2Ai8vrVdrA9J0gSMNVySrAP+K/AnbT3AxcD7W5OdwBVteUtbp21/dWu/Bbi1qr5WVZ8D5oAL22euqh6uqq8DtwJbjtOHJGkCxn3m8kfAbwL/1tZfCnypqp5u6weAtW15LfAoQNv+RGv/TH3ePgvVF+vjmyTZnmQ2yezhw4e/1e8oSZpnbOGS5CeBQ1W1f1x9fLuqakdVzVTVzJo1a6Y9HElaMVaN8divAn46yeXA6cAZwLuAM5OsamcW64CDrf1B4FzgQJJVwEuAI0P1Y4b3GVU/skgfkqQJGNuZS1W9tarWVdV6BjfkP1ZVPwd8HHhNa7YVuL0t727rtO0fq6pq9SvbbLLzgA3Ap4C7gA1tZthprY/dbZ+F+pAkTcA0nnP5LeDXkswxuD9yU6vfBLy01X8NuAagqu4DbgPuBz4KXF1V32hnJW8B9jCYjXZba7tYH5KkCRjnZbFnVNXfAH/Tlh9mMNNrfpungNcusP/1wPUj6ncAd4yoj+xDkjQZPqEvSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSepubOGS5PQkn0ryD0nuS/I/W/28JJ9MMpfkL5Oc1urPb+tzbfv6oWO9tdUfTHLpUH1zq80luWaoPrIPSdJkjPPM5WvAxVX1CuB8YHOSTcDvAe+squ8DHge2tfbbgMdb/Z2tHUk2AlcCPwBsBt6b5NQkpwLvAS4DNgKvb21ZpA9J0gSMLVxq4Ctt9XntU8DFwPtbfSdwRVve0tZp21+dJK1+a1V9rao+B8wBF7bPXFU9XFVfB24FtrR9FupDkjQBY73n0s4wPgscAvYC/wR8qaqebk0OAGvb8lrgUYC2/QngpcP1efssVH/pIn3MH9/2JLNJZg8fPvztfFVJ0pCxhktVfaOqzgfWMTjT+I/j7O+5qqodVTVTVTNr1qyZ9nAkacWYyGyxqvoS8HHgPwNnJlnVNq0DDrblg8C5AG37S4Ajw/V5+yxUP7JIH5KkCRjnbLE1Sc5syy8AfgJ4gEHIvKY12wrc3pZ3t3Xa9o9VVbX6lW022XnABuBTwF3AhjYz7DQGN/13t30W6kOSNAGrjt/kW/YyYGeb1XUKcFtVfTjJ/cCtSX4X+AxwU2t/E/BnSeaAowzCgqq6L8ltwP3A08DVVfUNgCRvAfYApwI3V9V97Vi/tUAfkqQJGFu4VNXdwA+NqD/M4P7L/PpTwGsXONb1wPUj6ncAdyy1D0nSZPiEviSpO8NFktTdksIlyZ1LqUmSBMe555LkdOCFwNlJVgNpm85ggQcTJUk63g39XwJ+FfguYD//Hi5PAn88xnFJkpaxRcOlqt4FvCvJf6uqd09oTJKkZW5JU5Gr6t1JfgRYP7xPVe0a07gkScvYksIlyZ8B3wt8FvhGKxdguEiSnmWpD1HOABvbq1UkSVrUUp9zuRf4znEORJK0ciz1zOVs4P4kn2LwC5MAVNVPj2VUkqRlbanh8j/GOQhJ0sqy1NlifzvugUiSVo6lzhb7MoPZYQCnAc8D/rWqzhjXwCRJy9dSz1xefGw5SYAtwKZxDUqStLw957ci18BfA5eOYTySpBVgqZfFfmZo9RQGz708NZYRSZKWvaXOFvupoeWngc8zuDQmSdKzLPWeyxvHPRBJ0sqx1B8LW5fkg0kOtc8Hkqwb9+AkScvTUm/o/ymwm8HvunwX8KFWkyTpWZYaLmuq6k+r6un2uQVYM8ZxSZKWsaWGy5Ekb0hyavu8ATgyzoFJkpavpYbLLwKvA74APAa8BviFMY1JkrTMLXUq8nXA1qp6HCDJWcA7GISOJEnfZKlnLj94LFgAquoo8EPjGZIkablbarickmT1sZV25rLUsx5J0klmqQHxB8DfJ3lfW38tcP14hiRJWu6W+oT+riSzwMWt9DNVdf/4hiVJWs6WfGmrhYmBIkk6ruf8yn1Jko7HcJEkdWe4SJK6M1wkSd2NLVySnJvk40nuT3Jfkl9p9bOS7E3yUPu7utWT5IYkc0nuTvLKoWNtbe0fSrJ1qH5BknvaPjckyWJ9SJImY5xnLk8Dv15VG4FNwNVJNgLXAHdW1QbgzrYOcBmwoX22AzfCMw9sXgtcBFwIXDsUFjcCbxrab3OrL9SHJGkCxhYuVfVYVX26LX8ZeABYy+DnkXe2ZjuBK9ryFmBXDewDzkzyMuBSYG9VHW2voNkLbG7bzqiqfVVVwK55xxrVhyRpAiZyzyXJegbvIvskcE5VPdY2fQE4py2vBR4d2u1Aqy1WPzCiziJ9zB/X9iSzSWYPHz783L+YJGmksYdLkhcBHwB+taqeHN7WzjhqnP0v1kdV7aiqmaqaWbPG3z6TpF7GGi5JnscgWP53Vf1VK3+xXdKi/T3U6geBc4d2X9dqi9XXjagv1ockaQLGOVsswE3AA1X1h0ObdgPHZnxtBW4fql/VZo1tAp5ol7b2AJckWd1u5F8C7GnbnkyyqfV11bxjjepDkjQB43xt/quAnwfuSfLZVvtt4O3AbUm2AY8w+IVLgDuAy4E54KvAG2Hw2zFJ3gbc1dpd135PBuDNwC3AC4CPtA+L9CFJmoCxhUtV/V8gC2x+9Yj2BVy9wLFuBm4eUZ8FXj6ifmRUH5KkyfAJfUlSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndrZr2ACSN3z9f95+mPQSdgL77v98ztmN75iJJ6m5s4ZLk5iSHktw7VDsryd4kD7W/q1s9SW5IMpfk7iSvHNpna2v/UJKtQ/ULktzT9rkhSRbrQ5I0OeM8c7kF2Dyvdg1wZ1VtAO5s6wCXARvaZztwIwyCArgWuAi4ELh2KCxuBN40tN/m4/QhSZqQsYVLVX0CODqvvAXY2ZZ3AlcM1XfVwD7gzCQvAy4F9lbV0ap6HNgLbG7bzqiqfVVVwK55xxrVhyRpQiZ9z+WcqnqsLX8BOKctrwUeHWp3oNUWqx8YUV+sj2dJsj3JbJLZw4cPfwtfR5I0ytRu6LczjppmH1W1o6pmqmpmzZo14xyKJJ1UJh0uX2yXtGh/D7X6QeDcoXbrWm2x+roR9cX6kCRNyKTDZTdwbMbXVuD2ofpVbdbYJuCJdmlrD3BJktXtRv4lwJ627ckkm9ossavmHWtUH5KkCRnbQ5RJ/gL4MeDsJAcYzPp6O3Bbkm3AI8DrWvM7gMuBOeCrwBsBqupokrcBd7V211XVsUkCb2YwI+0FwEfah0X6kCRNyNjCpapev8CmV49oW8DVCxznZuDmEfVZ4OUj6kdG9SFJmhyf0JckdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6W7HhkmRzkgeTzCW5ZtrjkaSTyYoMlySnAu8BLgM2Aq9PsnG6o5Kkk8eKDBfgQmCuqh6uqq8DtwJbpjwmSTpprJr2AMZkLfDo0PoB4KL5jZJsB7a31a8keXACYztZnA38y7QHMW15x9ZpD0HP5r/NY65Nj6N8z6jiSg2XJamqHcCOaY9jJUoyW1Uz0x6HNJ//NidjpV4WOwicO7S+rtUkSROwUsPlLmBDkvOSnAZcCeye8pgk6aSxIi+LVdXTSd4C7AFOBW6uqvumPKyTjZcbdaLy3+YEpKqmPQZJ0gqzUi+LSZKmyHCRJHVnuKgrX7ujE1WSm5McSnLvtMdyMjBc1I2v3dEJ7hZg87QHcbIwXNSTr93RCauqPgEcnfY4ThaGi3oa9dqdtVMai6QpMlwkSd0ZLurJ1+5IAgwX9eVrdyQBhos6qqqngWOv3XkAuM3X7uhEkeQvgL8Hvj/JgSTbpj2mlczXv0iSuvPMRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLtIEJDkzyZsn0M8VvixUJwLDRZqMM4Elh0sGvpX/n1cweCO1NFU+5yJNQJJjb4h+EPg48IPAauB5wO9U1e1J1jN4APWTwAXA5cBVwBuAwwxeCrq/qt6R5HsZ/LzBGuCrwJuAs4APA0+0z89W1T9N6CtK32TVtAcgnSSuAV5eVecnWQW8sKqeTHI2sC/JsdfkbAC2VtW+JD8M/CzwCgYh9Glgf2u3A/jlqnooyUXAe6vq4nacD1fV+yf55aT5DBdp8gL8ryT/Bfg3Bj9LcE7b9khV7WvLrwJur6qngKeSfAggyYuAHwHel+TYMZ8/qcFLS2G4SJP3cwwuZ11QVf8vyeeB09u2f13C/qcAX6qq88c0Punb5g19aTK+DLy4Lb8EONSC5ceB71lgn78DfirJ6e1s5ScBqupJ4HNJXgvP3Px/xYh+pKkxXKQJqKojwN8luRc4H5hJcg+DG/b/uMA+dzH4yYK7gY8A9zC4UQ+Ds59tSf4BuI9//znpW4HfSPKZdtNfmgpni0knsCQvqqqvJHkh8Alge1V9etrjko7Hey7SiW1HeyjydGCnwaLlwjMXSVJ33nORJHVnuEiSujNcJEndGS6SpO4MF0lSd/8fD89tvwDZbFEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a **binary classification** and the target variavel is skewed. The best metric for this binary classification is AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hot', 'Warm', 'Freezing', 'Lava Hot', 'Cold', 'Boiling Hot', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ord2 = df['ord_2'].unique()\n",
    "val_ord2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see in the ord_2 feature there are SIX categories (nan is not a category). We can map them from 0 to 5.\n",
    " This type of enconding categorical variables is known as **Label Enconding**, i.e.,\n",
    "we are encoding every category as a numerical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\": 1,\n",
    "    \"Cold\": 2,\n",
    "    \"Boiling Hot\": 3,\n",
    "    \"Hot\": 4,\n",
    "    \"Lava Hot\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'ord_2'] = df.ord_2.map(mapping)\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same using LabelEnconder from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('../input/cat_train.csv')\n",
    "\n",
    "# fill NaN values in ord_2 column to be able use LabelEncoder\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "# initialize LabelEncoder\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S: do not use this directly. fit first, then transform\n",
    "df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this directly in many tree-based models:\n",
    "- Decision trees\n",
    "- Random forest\n",
    "- Extra Trees\n",
    "- Or any kind of boosted trees model\n",
    "    - XGBoost\n",
    "    - GBM\n",
    "    - LightGBM\n",
    "\n",
    "This type of encoding cannot be used in linear models, support vector machines or\n",
    "neural networks as they expect data to be normalized (or standardized).\n",
    "\n",
    "For these type of models, we can binarize the data:\n",
    "- 0 -> 0 0 0\n",
    "- 1 -> 0 0 1\n",
    "- 2 -> 0 1 0\n",
    "- 3 -> 0 1 1\n",
    "- 4 -> 1 0 0\n",
    "- 5 -> 1 0 1\n",
    "\n",
    "This is can be seen as a **One-Hot Enconding** becasue only have ZERO's and ONE's.\n",
    "However, if this procdure genetares a lot of zeros, we only have interess in sparse than in dense matrix. In other words, we are only interess in ONE's than in ZERO's. This will occupy much less space in your computer.\n",
    "\n",
    "There are other ways to convert text to numerical variables. For example we can convert our *ord_2* using the amount of times some label appears in the collumn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84790, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv('../input/cat_train.csv')\n",
    "df[df.ord_2 == \"Boiling Hot\"].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Boiling Hot     84790\n",
       "Cold            97822\n",
       "Freezing       142726\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Warm           124239\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new column or replace this\n",
    "column by using the transform function of pandas along with groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          67508.0\n",
       "1         124239.0\n",
       "2         142726.0\n",
       "3          64840.0\n",
       "4          97822.0\n",
       "            ...   \n",
       "599995    142726.0\n",
       "599996     84790.0\n",
       "599997    142726.0\n",
       "599998    124239.0\n",
       "599999     84790.0\n",
       "Name: id, Length: 600000, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_2\"])[\"id\"].transform(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add counts of all the features or can also replace them or maybe group by\n",
    "multiple columns and their counts. For example, the following code counts by\n",
    "grouping on *ord_1* and *ord_2* columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>15634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Cold</td>\n",
       "      <td>17734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>26082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Hot</td>\n",
       "      <td>12428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>11919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Contributor</td>\n",
       "      <td>Warm</td>\n",
       "      <td>22774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>19477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Cold</td>\n",
       "      <td>22956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Hot</td>\n",
       "      <td>15792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>15078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Expert</td>\n",
       "      <td>Warm</td>\n",
       "      <td>28900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>13623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>15464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>22818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>10805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>10363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Warm</td>\n",
       "      <td>19899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Master</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Master</td>\n",
       "      <td>Cold</td>\n",
       "      <td>12364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Master</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>18035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Master</td>\n",
       "      <td>Hot</td>\n",
       "      <td>8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Master</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>8209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Master</td>\n",
       "      <td>Warm</td>\n",
       "      <td>15734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Cold</td>\n",
       "      <td>26271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>38233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Hot</td>\n",
       "      <td>17850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>17373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Novice</td>\n",
       "      <td>Warm</td>\n",
       "      <td>33263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_1        ord_2  count\n",
       "0   Contributor  Boiling Hot  15634\n",
       "1   Contributor         Cold  17734\n",
       "2   Contributor     Freezing  26082\n",
       "3   Contributor          Hot  12428\n",
       "4   Contributor     Lava Hot  11919\n",
       "5   Contributor         Warm  22774\n",
       "6        Expert  Boiling Hot  19477\n",
       "7        Expert         Cold  22956\n",
       "8        Expert     Freezing  33249\n",
       "9        Expert          Hot  15792\n",
       "10       Expert     Lava Hot  15078\n",
       "11       Expert         Warm  28900\n",
       "12  Grandmaster  Boiling Hot  13623\n",
       "13  Grandmaster         Cold  15464\n",
       "14  Grandmaster     Freezing  22818\n",
       "15  Grandmaster          Hot  10805\n",
       "16  Grandmaster     Lava Hot  10363\n",
       "17  Grandmaster         Warm  19899\n",
       "18       Master  Boiling Hot  10800\n",
       "19       Master         Cold  12364\n",
       "20       Master     Freezing  18035\n",
       "21       Master          Hot   8594\n",
       "22       Master     Lava Hot   8209\n",
       "23       Master         Warm  15734\n",
       "24       Novice  Boiling Hot  22718\n",
       "25       Novice         Cold  26271\n",
       "26       Novice     Freezing  38233\n",
       "27       Novice          Hot  17850\n",
       "28       Novice     Lava Hot  17373\n",
       "29       Novice         Warm  33263"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"ord_1\", \"ord_2\"])[\"id\"].count().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new features combine them\n",
    "One more trick is to create new features from these categorical variables. You can\n",
    "create new categorical features from existing features, and this can be done in an\n",
    "effortless manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Contributor_Hot\n",
       "1                Grandmaster_Warm\n",
       "2                    nan_Freezing\n",
       "3                 Novice_Lava Hot\n",
       "4                Grandmaster_Cold\n",
       "                   ...           \n",
       "599995            Novice_Freezing\n",
       "599996         Novice_Boiling Hot\n",
       "599997       Contributor_Freezing\n",
       "599998                Master_Warm\n",
       "599999    Contributor_Boiling Hot\n",
       "Name: new_feature, Length: 600000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_feature\"] = (df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str))\n",
    "df.new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So which categories should we combine? Well, there isn't an easy answer to that. It\n",
    "depends on your data and the types of features. Some domain knowledge might be\n",
    "useful for creating features like this. **But if you don’t have concerns about memory\n",
    "and CPU usage, you can go for a greedy approach where you can create many such\n",
    "combinations and then use a model to decide which features are useful and keep\n",
    "them.**\n",
    "\n",
    "Whenever you get categorical variables, follow these simple steps:\n",
    "- fill the NaN values (this is very important!)\n",
    "- convert them to integers by applying label encoding using LabelEncoder\n",
    "of scikit-learn or by using a mapping dictionary. If you didn’t fill up NaN\n",
    "values with something, you might have to take care of them in this step\n",
    "- create one-hot encoding. Yes, you can skip binarization!\n",
    "- go for modelling! I mean the machine learning one. Not on the ramp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling with Nan values in categorical variable\n",
    "Another way of\n",
    "handling NaN values is to treat them as a completely new category. This is the most\n",
    "preferred way of handling NaN values. And can be achieved in a very simple\n",
    "manner if you are using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 18075 NaN values in this column that we didn’t even consider\n",
    "using previously. With the addition of this new category, the total number of\n",
    "categories have now increased from 6 to 7. This is okay because now when we build\n",
    "our models, we will also consider NaN. The more relevant information we have,\n",
    "the better the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you have a fixed test set, you can add your test data to training to know about the\n",
    "categories in a given feature. This is very similar to semi-supervised learning in\n",
    "which you use data which is not available for training to improve your model. This\n",
    "will also take care of rare values that appear very less number of times in training\n",
    "data but are in abundance in test data. Your model will be more robust.\n",
    "Many people think that this idea overfits. It may or may not overfit. There is a\n",
    "simple fix for that. **If you design your cross-validation in such a way that it\n",
    "replicates the prediction process when you run your model on test data, then it’s\n",
    "never going to overfit. It means that the first step should be the separation of folds,\n",
    "and in each fold, you should apply the same pre-processing that you want to apply\n",
    "to test data.** Suppose you want to concatenate training and test data, then in each\n",
    "fold you must concatenate training and validation data and also make sure that your\n",
    "validation dataset replicates the test set. In this specific case, you must design your\n",
    "validation sets in such a way that it has categories which are “unseen” in the training\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read training data\n",
    "train = pd.read_csv(\"../input/cat_train.csv\")\n",
    "\n",
    "# read test data\n",
    "test = pd.read_csv(\"../input/cat_test_csv\")\n",
    "\n",
    "# create a fake target column for test data\n",
    "# since this column doesn't exist\n",
    "test.loc[:, \"target\"] = -1\n",
    "\n",
    "# concatenate both training and test data\n",
    "data = pd.concat([train,test]).reset_index(drop=True)\n",
    "\n",
    "# make a list of feature we are interested in\n",
    "# id and target is something we should not encode\n",
    "features = [x for x in train.columns if x is not [\"id\",\"target\"]]\n",
    "\n",
    "#loop over the features list\n",
    "for feat in features:\n",
    "    # create a new instance of LabelEncoder for each feature\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # note the trick here\n",
    "    # since its categorical data, we fillna with a string\n",
    "    # and we convert all the data to string type\n",
    "    # so, no matter its int or float, its converted to string\n",
    "    # int/float but categorical!!!\n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "    \n",
    "    # we can use fit_transform here as we do not\n",
    "    # have any extra test data that we need to\n",
    "    # transform on separately\n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
    "    \n",
    "# split the training and test data again\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It must be noted that this trick will **not work in a live setting**. For example, let’s say\n",
    "you are in a company that builds a real-time bidding solution (RTB). RTB systems\n",
    "bid on every user they see online to buy ad space. The features that can be used for\n",
    "such a model may include pages viewed in a website. Let’s assume that features are\n",
    "the last five categories/pages visited by the user. In this case, if the website\n",
    "introduces new categories, we will no longer be able to predict accurately. Our\n",
    "model, in this case, will fail. **A situation like this can be avoided by using an\n",
    "“unknown” category.** So, if during live testing, we get new categories\n",
    "that we have not seen before, we will mark them as “NONE”.\n",
    "\n",
    "This is very similar to natural language processing problems. We always build a\n",
    "model based on a fixed vocabulary. Increasing the size of the vocabulary increases\n",
    "the size of the model. Transformer models like BERT are trained on ~30000 words\n",
    "(for English). **So, when we have a new word coming in, we mark it as UNK\n",
    "(unknown).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U', 'X', 'P', 'C', 'Q', 'R', 'Y', 'N', 'I', 'O', 'M', 'E', 'V',\n",
       "       'K', 'G', 'B', 'H', nan, 'T', 'W', 'A', 'F', 'D', 'S', 'J', 'L',\n",
       "       'Z'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N       39978\n",
       "P       37890\n",
       "Y       36657\n",
       "A       36633\n",
       "R       33045\n",
       "U       32897\n",
       "M       32504\n",
       "X       32347\n",
       "C       32112\n",
       "H       31189\n",
       "Q       30145\n",
       "T       29723\n",
       "O       25610\n",
       "B       25212\n",
       "E       21871\n",
       "K       21676\n",
       "I       19805\n",
       "NONE    17930\n",
       "D       17284\n",
       "F       16721\n",
       "W        8268\n",
       "Z        5790\n",
       "S        4595\n",
       "G        3404\n",
       "V        3107\n",
       "J        1950\n",
       "L        1657\n",
       "Name: ord_4, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_4.fillna(\"NONE\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This approach will also ensure that the model works in a live setting**, even if you\n",
    "have new categories.\n",
    "\n",
    "Now we have everything we need to approach any kind of problem with categorical\n",
    "variables in it. Let’s try building our first model and try to improve its performance\n",
    "in a step-wise manner.\n",
    "\n",
    "Before going to any kind of model building, it’s essential to take care of cross-\n",
    "validation. We have already seen the label/target distribution, and we know that it\n",
    "is a **binary classification problem with skewed targets.** Thus, we will be using\n",
    "**StratifiedKFold** to split the data here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
